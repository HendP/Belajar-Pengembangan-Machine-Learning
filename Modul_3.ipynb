{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modul 3",
      "provenance": [],
      "authorship_tag": "ABX9TyMv8Oq85yR3sQ7OZWz0gzU1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agungtriu/Belajar-Pengembangan-Machine-Learning/blob/master/Modul_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNwtHsoA87ZE",
        "colab_type": "text"
      },
      "source": [
        "# Menggunakan Model untuk Melakukan Prediksi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrfZc0IF9NYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tayRMdNL9P6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = np.array([1.0,  2.0, 3.0, 4.0, 5.0, 6.0], dtype=float)\n",
        "ys = np.array([4.0, 6.0, 8.0, 10.0, 12.0, 14.0], dtype=float)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMU-cKEN9Tsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOClqoMO9VjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGKOl9XW9Xyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "048d2b0a-28d5-4dac-ad50-15a757e98593"
      },
      "source": [
        "model.fit(xs, ys, epochs=150)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 221.1182\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 102.4760\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 47.5639\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 22.1479\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.3837\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9379\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4164\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2485\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7069\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4554\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3380\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2828\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2563\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2431\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2361\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2320\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2291\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2270\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2251\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2233\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2216\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2200\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2184\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2168\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2152\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2136\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2121\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2105\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2090\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2075\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2060\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2045\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2030\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2015\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2000\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1986\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1971\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1957\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1943\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1928\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1914\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1900\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1887\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1873\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1859\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1846\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1832\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1819\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1806\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1792\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1779\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1766\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1754\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1741\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1728\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1716\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1703\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1691\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1678\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1666\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1654\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1642\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1630\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1618\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1606\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1595\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1583\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1571\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1560\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1549\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1537\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1526\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1515\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 902us/step - loss: 0.1504\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1493\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1482\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1471\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1461\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 873us/step - loss: 0.1450\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1439\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1429\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1418\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1408\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1398\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1388\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1378\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1368\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1358\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1348\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1338\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1328\n",
            "Epoch 92/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1318\n",
            "Epoch 93/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1309\n",
            "Epoch 94/150\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1299\n",
            "Epoch 95/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1290\n",
            "Epoch 96/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1280\n",
            "Epoch 97/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1271\n",
            "Epoch 98/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1262\n",
            "Epoch 99/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1253\n",
            "Epoch 100/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1244\n",
            "Epoch 101/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1234\n",
            "Epoch 102/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1225\n",
            "Epoch 103/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1217\n",
            "Epoch 104/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1208\n",
            "Epoch 105/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1199\n",
            "Epoch 106/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1190\n",
            "Epoch 107/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1182\n",
            "Epoch 108/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1173\n",
            "Epoch 109/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1164\n",
            "Epoch 110/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1156\n",
            "Epoch 111/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1147\n",
            "Epoch 112/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1139\n",
            "Epoch 113/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1131\n",
            "Epoch 114/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1123\n",
            "Epoch 115/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1114\n",
            "Epoch 116/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1106\n",
            "Epoch 117/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1098\n",
            "Epoch 118/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1090\n",
            "Epoch 119/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1082\n",
            "Epoch 120/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1074\n",
            "Epoch 121/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1067\n",
            "Epoch 122/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1059\n",
            "Epoch 123/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1051\n",
            "Epoch 124/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1043\n",
            "Epoch 125/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1036\n",
            "Epoch 126/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1028\n",
            "Epoch 127/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1021\n",
            "Epoch 128/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1013\n",
            "Epoch 129/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1006\n",
            "Epoch 130/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0999\n",
            "Epoch 131/150\n",
            "1/1 [==============================] - 0s 938us/step - loss: 0.0991\n",
            "Epoch 132/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0984\n",
            "Epoch 133/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0977\n",
            "Epoch 134/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0970\n",
            "Epoch 135/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0963\n",
            "Epoch 136/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0956\n",
            "Epoch 137/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0949\n",
            "Epoch 138/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0942\n",
            "Epoch 139/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0935\n",
            "Epoch 140/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0928\n",
            "Epoch 141/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 142/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0915\n",
            "Epoch 143/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0908\n",
            "Epoch 144/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0901\n",
            "Epoch 145/150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0895\n",
            "Epoch 146/150\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0888\n",
            "Epoch 147/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0882\n",
            "Epoch 148/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0875\n",
            "Epoch 149/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0869\n",
            "Epoch 150/150\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f817dd135f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwm__okl9alN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69a000c7-2588-40cf-98d4-10428740463e"
      },
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22.891165]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tct2BFqP9G1z",
        "colab_type": "text"
      },
      "source": [
        "# Build dan Train Neural Network Model Tensorflow dan Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sICjonWDtQLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "80d8dfa0-3ae1-4a9d-e0dd-9b2fcdc6e1e4"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('citrus.csv')\n",
        "df.info()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   name      10000 non-null  object \n",
            " 1   diameter  10000 non-null  float64\n",
            " 2   weight    10000 non-null  float64\n",
            " 3   red       10000 non-null  int64  \n",
            " 4   green     10000 non-null  int64  \n",
            " 5   blue      10000 non-null  int64  \n",
            "dtypes: float64(2), int64(3), object(1)\n",
            "memory usage: 468.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNdxjNU6uGmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "a997e2a6-14cb-4ae2-82d7-564155fc72d0"
      },
      "source": [
        "df.head(10000)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>diameter</th>\n",
              "      <th>weight</th>\n",
              "      <th>red</th>\n",
              "      <th>green</th>\n",
              "      <th>blue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>orange</td>\n",
              "      <td>2.96</td>\n",
              "      <td>86.76</td>\n",
              "      <td>172</td>\n",
              "      <td>85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>orange</td>\n",
              "      <td>3.91</td>\n",
              "      <td>88.05</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>orange</td>\n",
              "      <td>4.42</td>\n",
              "      <td>95.17</td>\n",
              "      <td>156</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>orange</td>\n",
              "      <td>4.47</td>\n",
              "      <td>95.60</td>\n",
              "      <td>163</td>\n",
              "      <td>81</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>orange</td>\n",
              "      <td>4.48</td>\n",
              "      <td>95.76</td>\n",
              "      <td>161</td>\n",
              "      <td>72</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.35</td>\n",
              "      <td>253.89</td>\n",
              "      <td>149</td>\n",
              "      <td>77</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.41</td>\n",
              "      <td>254.67</td>\n",
              "      <td>148</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.59</td>\n",
              "      <td>256.50</td>\n",
              "      <td>168</td>\n",
              "      <td>82</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.92</td>\n",
              "      <td>260.14</td>\n",
              "      <td>142</td>\n",
              "      <td>72</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>16.45</td>\n",
              "      <td>261.51</td>\n",
              "      <td>152</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            name  diameter  weight  red  green  blue\n",
              "0         orange      2.96   86.76  172     85     2\n",
              "1         orange      3.91   88.05  166     78     3\n",
              "2         orange      4.42   95.17  156     81     2\n",
              "3         orange      4.47   95.60  163     81     4\n",
              "4         orange      4.48   95.76  161     72     9\n",
              "...          ...       ...     ...  ...    ...   ...\n",
              "9995  grapefruit     15.35  253.89  149     77    20\n",
              "9996  grapefruit     15.41  254.67  148     68     7\n",
              "9997  grapefruit     15.59  256.50  168     82    20\n",
              "9998  grapefruit     15.92  260.14  142     72    11\n",
              "9999  grapefruit     16.45  261.51  152     74     2\n",
              "\n",
              "[10000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmN1hSV_uI7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5be00a31-0d46-4d5d-a3a3-4c1a04e62ca5"
      },
      "source": [
        "df.name[df.name == 'orange'] = 0\n",
        "df.name[df.name == 'grapefruit'] = 1"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtxdn-tGumXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "5b4a2cb3-b56f-457d-896a-b049a2142125"
      },
      "source": [
        "df.head(10000)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>diameter</th>\n",
              "      <th>weight</th>\n",
              "      <th>red</th>\n",
              "      <th>green</th>\n",
              "      <th>blue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2.96</td>\n",
              "      <td>86.76</td>\n",
              "      <td>172</td>\n",
              "      <td>85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3.91</td>\n",
              "      <td>88.05</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>4.42</td>\n",
              "      <td>95.17</td>\n",
              "      <td>156</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>95.60</td>\n",
              "      <td>163</td>\n",
              "      <td>81</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.48</td>\n",
              "      <td>95.76</td>\n",
              "      <td>161</td>\n",
              "      <td>72</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>15.35</td>\n",
              "      <td>253.89</td>\n",
              "      <td>149</td>\n",
              "      <td>77</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>15.41</td>\n",
              "      <td>254.67</td>\n",
              "      <td>148</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>15.59</td>\n",
              "      <td>256.50</td>\n",
              "      <td>168</td>\n",
              "      <td>82</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>15.92</td>\n",
              "      <td>260.14</td>\n",
              "      <td>142</td>\n",
              "      <td>72</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>16.45</td>\n",
              "      <td>261.51</td>\n",
              "      <td>152</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     name  diameter  weight  red  green  blue\n",
              "0       0      2.96   86.76  172     85     2\n",
              "1       0      3.91   88.05  166     78     3\n",
              "2       0      4.42   95.17  156     81     2\n",
              "3       0      4.47   95.60  163     81     4\n",
              "4       0      4.48   95.76  161     72     9\n",
              "...   ...       ...     ...  ...    ...   ...\n",
              "9995    1     15.35  253.89  149     77    20\n",
              "9996    1     15.41  254.67  148     68     7\n",
              "9997    1     15.59  256.50  168     82    20\n",
              "9998    1     15.92  260.14  142     72    11\n",
              "9999    1     16.45  261.51  152     74     2\n",
              "\n",
              "[10000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogLoWBIMuou_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "815affe4-7f01-47ec-e5cb-1f3852256761"
      },
      "source": [
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2.96, 86.76, 172, 85, 2],\n",
              "       [0, 3.91, 88.05, 166, 78, 3],\n",
              "       [0, 4.42, 95.17, 156, 81, 2],\n",
              "       ...,\n",
              "       [1, 15.59, 256.5, 168, 82, 20],\n",
              "       [1, 15.92, 260.14, 142, 72, 11],\n",
              "       [1, 16.45, 261.51, 152, 74, 2]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnfln06ovhD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pilih 4 kolom terakhir sebagai atribut\n",
        "X = dataset[:,1:6]\n",
        "y = np.array(list(dataset[:,0]), dtype=np.float)\n",
        "# bilangan sebelum koma untuk memilih baris pada dataframe\n",
        "# bilangan setelah koma untuk memilih kolom pada dataframe"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEDG3HCMvh9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5eb4856e-8757-43d8-954b-1902ab4eb1eb"
      },
      "source": [
        "# Normalization\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.74025974, 0.63529412, 0.        ],\n",
              "       [0.07042254, 0.00738197, 0.66233766, 0.55294118, 0.01851852],\n",
              "       [0.10822832, 0.04812589, 0.53246753, 0.58823529, 0.        ],\n",
              "       ...,\n",
              "       [0.93624907, 0.97133047, 0.68831169, 0.6       , 0.33333333],\n",
              "       [0.96071164, 0.99216023, 0.35064935, 0.48235294, 0.16666667],\n",
              "       [1.        , 1.        , 0.48051948, 0.50588235, 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVu4b3TR2HRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6527b5d-6d7b-4f1d-b8fe-958a068175b1"
      },
      "source": [
        "y"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-pPL1Lhvzmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pisahkan data training dan testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7v-rEMHx-sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([    \n",
        "                    Dense(32, activation='relu', input_shape=(5,)),    \n",
        "                    Dense(32, activation='relu'),    \n",
        "                    Dense(1, activation='sigmoid'),])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocCXNb_GyTmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a6ce57c-27b3-4051-91f7-6e46414c4bfb"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=100)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "219/219 [==============================] - 0s 902us/step - loss: 0.6656 - accuracy: 0.5934\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 0s 888us/step - loss: 0.6252 - accuracy: 0.8171\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 0s 968us/step - loss: 0.5745 - accuracy: 0.8851\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 0s 907us/step - loss: 0.5041 - accuracy: 0.9119\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 0s 960us/step - loss: 0.4176 - accuracy: 0.9173\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 0s 934us/step - loss: 0.3371 - accuracy: 0.9246\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 0s 946us/step - loss: 0.2778 - accuracy: 0.9254\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 0s 897us/step - loss: 0.2397 - accuracy: 0.9266\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 0s 952us/step - loss: 0.2171 - accuracy: 0.9273\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 0s 959us/step - loss: 0.2032 - accuracy: 0.9277\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 0s 938us/step - loss: 0.1948 - accuracy: 0.9273\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 0s 890us/step - loss: 0.1889 - accuracy: 0.9270\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 0s 991us/step - loss: 0.1855 - accuracy: 0.9270\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9274\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 0s 952us/step - loss: 0.1809 - accuracy: 0.9261\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 0s 892us/step - loss: 0.1804 - accuracy: 0.9274\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 0s 910us/step - loss: 0.1792 - accuracy: 0.9270\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 0s 915us/step - loss: 0.1787 - accuracy: 0.9283\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 0s 961us/step - loss: 0.1778 - accuracy: 0.9267\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 0s 917us/step - loss: 0.1775 - accuracy: 0.9271\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 0s 913us/step - loss: 0.1779 - accuracy: 0.9269\n",
            "Epoch 22/100\n",
            "219/219 [==============================] - 0s 915us/step - loss: 0.1771 - accuracy: 0.9284\n",
            "Epoch 23/100\n",
            "219/219 [==============================] - 0s 908us/step - loss: 0.1772 - accuracy: 0.9277\n",
            "Epoch 24/100\n",
            "219/219 [==============================] - 0s 951us/step - loss: 0.1772 - accuracy: 0.9281\n",
            "Epoch 25/100\n",
            "219/219 [==============================] - 0s 915us/step - loss: 0.1770 - accuracy: 0.9267\n",
            "Epoch 26/100\n",
            "219/219 [==============================] - 0s 917us/step - loss: 0.1770 - accuracy: 0.9267\n",
            "Epoch 27/100\n",
            "219/219 [==============================] - 0s 899us/step - loss: 0.1772 - accuracy: 0.9267\n",
            "Epoch 28/100\n",
            "219/219 [==============================] - 0s 959us/step - loss: 0.1769 - accuracy: 0.9261\n",
            "Epoch 29/100\n",
            "219/219 [==============================] - 0s 974us/step - loss: 0.1767 - accuracy: 0.9279\n",
            "Epoch 30/100\n",
            "219/219 [==============================] - 0s 914us/step - loss: 0.1762 - accuracy: 0.9269\n",
            "Epoch 31/100\n",
            "219/219 [==============================] - 0s 896us/step - loss: 0.1765 - accuracy: 0.9284\n",
            "Epoch 32/100\n",
            "219/219 [==============================] - 0s 947us/step - loss: 0.1767 - accuracy: 0.9284\n",
            "Epoch 33/100\n",
            "219/219 [==============================] - 0s 909us/step - loss: 0.1764 - accuracy: 0.9284\n",
            "Epoch 34/100\n",
            "219/219 [==============================] - 0s 942us/step - loss: 0.1765 - accuracy: 0.9280\n",
            "Epoch 35/100\n",
            "219/219 [==============================] - 0s 882us/step - loss: 0.1763 - accuracy: 0.9277\n",
            "Epoch 36/100\n",
            "219/219 [==============================] - 0s 901us/step - loss: 0.1765 - accuracy: 0.9276\n",
            "Epoch 37/100\n",
            "219/219 [==============================] - 0s 902us/step - loss: 0.1763 - accuracy: 0.9274\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - 0s 914us/step - loss: 0.1763 - accuracy: 0.9274\n",
            "Epoch 39/100\n",
            "219/219 [==============================] - 0s 987us/step - loss: 0.1765 - accuracy: 0.9273\n",
            "Epoch 40/100\n",
            "219/219 [==============================] - 0s 897us/step - loss: 0.1763 - accuracy: 0.9276\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - 0s 939us/step - loss: 0.1762 - accuracy: 0.9286\n",
            "Epoch 42/100\n",
            "219/219 [==============================] - 0s 908us/step - loss: 0.1762 - accuracy: 0.9270\n",
            "Epoch 43/100\n",
            "219/219 [==============================] - 0s 891us/step - loss: 0.1762 - accuracy: 0.9271\n",
            "Epoch 44/100\n",
            "219/219 [==============================] - 0s 985us/step - loss: 0.1761 - accuracy: 0.9267\n",
            "Epoch 45/100\n",
            "219/219 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9280\n",
            "Epoch 46/100\n",
            "219/219 [==============================] - 0s 981us/step - loss: 0.1759 - accuracy: 0.9284\n",
            "Epoch 47/100\n",
            "219/219 [==============================] - 0s 898us/step - loss: 0.1759 - accuracy: 0.9266\n",
            "Epoch 48/100\n",
            "219/219 [==============================] - 0s 984us/step - loss: 0.1766 - accuracy: 0.9271\n",
            "Epoch 49/100\n",
            "219/219 [==============================] - 0s 901us/step - loss: 0.1765 - accuracy: 0.9261\n",
            "Epoch 50/100\n",
            "219/219 [==============================] - 0s 921us/step - loss: 0.1765 - accuracy: 0.9263\n",
            "Epoch 51/100\n",
            "219/219 [==============================] - 0s 914us/step - loss: 0.1761 - accuracy: 0.9279\n",
            "Epoch 52/100\n",
            "219/219 [==============================] - 0s 887us/step - loss: 0.1765 - accuracy: 0.9264\n",
            "Epoch 53/100\n",
            "219/219 [==============================] - 0s 974us/step - loss: 0.1757 - accuracy: 0.9279\n",
            "Epoch 54/100\n",
            "219/219 [==============================] - 0s 872us/step - loss: 0.1760 - accuracy: 0.9284\n",
            "Epoch 55/100\n",
            "219/219 [==============================] - 0s 903us/step - loss: 0.1762 - accuracy: 0.9269\n",
            "Epoch 56/100\n",
            "219/219 [==============================] - 0s 889us/step - loss: 0.1758 - accuracy: 0.9290\n",
            "Epoch 57/100\n",
            "219/219 [==============================] - 0s 917us/step - loss: 0.1757 - accuracy: 0.9293\n",
            "Epoch 58/100\n",
            "219/219 [==============================] - 0s 962us/step - loss: 0.1761 - accuracy: 0.9276\n",
            "Epoch 59/100\n",
            "219/219 [==============================] - 0s 869us/step - loss: 0.1762 - accuracy: 0.9280\n",
            "Epoch 60/100\n",
            "219/219 [==============================] - 0s 904us/step - loss: 0.1763 - accuracy: 0.9283\n",
            "Epoch 61/100\n",
            "219/219 [==============================] - 0s 886us/step - loss: 0.1762 - accuracy: 0.9269\n",
            "Epoch 62/100\n",
            "219/219 [==============================] - 0s 911us/step - loss: 0.1758 - accuracy: 0.9287\n",
            "Epoch 63/100\n",
            "219/219 [==============================] - 0s 955us/step - loss: 0.1761 - accuracy: 0.9263\n",
            "Epoch 64/100\n",
            "219/219 [==============================] - 0s 957us/step - loss: 0.1760 - accuracy: 0.9267\n",
            "Epoch 65/100\n",
            "219/219 [==============================] - 0s 930us/step - loss: 0.1754 - accuracy: 0.9306\n",
            "Epoch 66/100\n",
            "219/219 [==============================] - 0s 926us/step - loss: 0.1761 - accuracy: 0.9266\n",
            "Epoch 67/100\n",
            "219/219 [==============================] - 0s 928us/step - loss: 0.1755 - accuracy: 0.9281\n",
            "Epoch 68/100\n",
            "219/219 [==============================] - 0s 910us/step - loss: 0.1760 - accuracy: 0.9277\n",
            "Epoch 69/100\n",
            "219/219 [==============================] - 0s 954us/step - loss: 0.1760 - accuracy: 0.9281\n",
            "Epoch 70/100\n",
            "219/219 [==============================] - 0s 922us/step - loss: 0.1761 - accuracy: 0.9279\n",
            "Epoch 71/100\n",
            "219/219 [==============================] - 0s 898us/step - loss: 0.1758 - accuracy: 0.9266\n",
            "Epoch 72/100\n",
            "219/219 [==============================] - 0s 893us/step - loss: 0.1759 - accuracy: 0.9271\n",
            "Epoch 73/100\n",
            "219/219 [==============================] - 0s 965us/step - loss: 0.1754 - accuracy: 0.9270\n",
            "Epoch 74/100\n",
            "219/219 [==============================] - 0s 919us/step - loss: 0.1753 - accuracy: 0.9263\n",
            "Epoch 75/100\n",
            "219/219 [==============================] - 0s 875us/step - loss: 0.1755 - accuracy: 0.9283\n",
            "Epoch 76/100\n",
            "219/219 [==============================] - 0s 890us/step - loss: 0.1760 - accuracy: 0.9276\n",
            "Epoch 77/100\n",
            "219/219 [==============================] - 0s 915us/step - loss: 0.1754 - accuracy: 0.9283\n",
            "Epoch 78/100\n",
            "219/219 [==============================] - 0s 983us/step - loss: 0.1757 - accuracy: 0.9263\n",
            "Epoch 79/100\n",
            "219/219 [==============================] - 0s 876us/step - loss: 0.1756 - accuracy: 0.9270\n",
            "Epoch 80/100\n",
            "219/219 [==============================] - 0s 903us/step - loss: 0.1760 - accuracy: 0.9276\n",
            "Epoch 81/100\n",
            "219/219 [==============================] - 0s 949us/step - loss: 0.1754 - accuracy: 0.9271\n",
            "Epoch 82/100\n",
            "219/219 [==============================] - 0s 978us/step - loss: 0.1754 - accuracy: 0.9276\n",
            "Epoch 83/100\n",
            "219/219 [==============================] - 0s 935us/step - loss: 0.1754 - accuracy: 0.9276\n",
            "Epoch 84/100\n",
            "219/219 [==============================] - 0s 889us/step - loss: 0.1752 - accuracy: 0.9289\n",
            "Epoch 85/100\n",
            "219/219 [==============================] - 0s 946us/step - loss: 0.1752 - accuracy: 0.9276\n",
            "Epoch 86/100\n",
            "219/219 [==============================] - 0s 897us/step - loss: 0.1757 - accuracy: 0.9283\n",
            "Epoch 87/100\n",
            "219/219 [==============================] - 0s 875us/step - loss: 0.1752 - accuracy: 0.9271\n",
            "Epoch 88/100\n",
            "219/219 [==============================] - 0s 905us/step - loss: 0.1753 - accuracy: 0.9273\n",
            "Epoch 89/100\n",
            "219/219 [==============================] - 0s 884us/step - loss: 0.1754 - accuracy: 0.9273\n",
            "Epoch 90/100\n",
            "219/219 [==============================] - 0s 979us/step - loss: 0.1752 - accuracy: 0.9286\n",
            "Epoch 91/100\n",
            "219/219 [==============================] - 0s 888us/step - loss: 0.1752 - accuracy: 0.9266\n",
            "Epoch 92/100\n",
            "219/219 [==============================] - 0s 903us/step - loss: 0.1753 - accuracy: 0.9280\n",
            "Epoch 93/100\n",
            "219/219 [==============================] - 0s 976us/step - loss: 0.1753 - accuracy: 0.9281\n",
            "Epoch 94/100\n",
            "219/219 [==============================] - 0s 906us/step - loss: 0.1755 - accuracy: 0.9273\n",
            "Epoch 95/100\n",
            "219/219 [==============================] - 0s 982us/step - loss: 0.1753 - accuracy: 0.9283\n",
            "Epoch 96/100\n",
            "219/219 [==============================] - 0s 916us/step - loss: 0.1752 - accuracy: 0.9296\n",
            "Epoch 97/100\n",
            "219/219 [==============================] - 0s 930us/step - loss: 0.1752 - accuracy: 0.9263\n",
            "Epoch 98/100\n",
            "219/219 [==============================] - 0s 965us/step - loss: 0.1750 - accuracy: 0.9266\n",
            "Epoch 99/100\n",
            "219/219 [==============================] - 0s 902us/step - loss: 0.1746 - accuracy: 0.9261\n",
            "Epoch 100/100\n",
            "219/219 [==============================] - 0s 910us/step - loss: 0.1750 - accuracy: 0.9289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f817e5df550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo3bPiig0nGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1394a5a4-c997-4a7e-bbf0-296b821586d7"
      },
      "source": [
        "model.evaluate(X_test, Y_test)\n",
        "# elemen pertama adalah loss dan elemen kedua adalah akurasi"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 0s 798us/step - loss: 0.1858 - accuracy: 0.9260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18575893342494965, 0.9259999990463257]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFsAIUcZ9gUE",
        "colab_type": "text"
      },
      "source": [
        "# Bangun Model untuk Klasifikasi Dua Kelas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvnknRor9fTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIH8Vmpx9oh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "c6478b45-5c43-428d-dffe-40875fe528d6"
      },
      "source": [
        "df = pd.read_csv('Iris.csv')\n",
        "df"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  ...  PetalWidthCm         Species\n",
              "0      1            5.1  ...           0.2     Iris-setosa\n",
              "1      2            4.9  ...           0.2     Iris-setosa\n",
              "2      3            4.7  ...           0.2     Iris-setosa\n",
              "3      4            4.6  ...           0.2     Iris-setosa\n",
              "4      5            5.0  ...           0.2     Iris-setosa\n",
              "..   ...            ...  ...           ...             ...\n",
              "145  146            6.7  ...           2.3  Iris-virginica\n",
              "146  147            6.3  ...           1.9  Iris-virginica\n",
              "147  148            6.5  ...           2.0  Iris-virginica\n",
              "148  149            6.2  ...           2.3  Iris-virginica\n",
              "149  150            5.9  ...           1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFZi8Rda9yTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns='Id')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vpkGitu93Er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e59ea8cf-2bee-419b-81e9-8dc4a2870f28"
      },
      "source": [
        "category = pd.get_dummies(df.Species)\n",
        "category"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "0              1                0               0\n",
              "1              1                0               0\n",
              "2              1                0               0\n",
              "3              1                0               0\n",
              "4              1                0               0\n",
              "..           ...              ...             ...\n",
              "145            0                0               1\n",
              "146            0                0               1\n",
              "147            0                0               1\n",
              "148            0                0               1\n",
              "149            0                0               1\n",
              "\n",
              "[150 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX_xrg7X-DLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "ae83c6bb-9300-4178-a2a7-da1bcd1ae9f3"
      },
      "source": [
        "new_df = pd.concat([df, category], axis=1)\n",
        "new_df = new_df.drop(columns='Species')\n",
        "new_df"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     SepalLengthCm  SepalWidthCm  ...  Iris-versicolor  Iris-virginica\n",
              "0              5.1           3.5  ...                0               0\n",
              "1              4.9           3.0  ...                0               0\n",
              "2              4.7           3.2  ...                0               0\n",
              "3              4.6           3.1  ...                0               0\n",
              "4              5.0           3.6  ...                0               0\n",
              "..             ...           ...  ...              ...             ...\n",
              "145            6.7           3.0  ...                0               1\n",
              "146            6.3           2.5  ...                0               1\n",
              "147            6.5           3.0  ...                0               1\n",
              "148            6.2           3.4  ...                0               1\n",
              "149            5.9           3.0  ...                0               1\n",
              "\n",
              "[150 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9omyEgb-HL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ab067a2c-554a-46c0-e2a7-93b48d51f864"
      },
      "source": [
        "dataset = new_df.values\n",
        "dataset"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, ..., 1. , 0. , 0. ],\n",
              "       [4.9, 3. , 1.4, ..., 1. , 0. , 0. ],\n",
              "       [4.7, 3.2, 1.3, ..., 1. , 0. , 0. ],\n",
              "       ...,\n",
              "       [6.5, 3. , 5.2, ..., 0. , 0. , 1. ],\n",
              "       [6.2, 3.4, 5.4, ..., 0. , 0. , 1. ],\n",
              "       [5.9, 3. , 5.1, ..., 0. , 0. , 1. ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijq943IG-LRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pilih 4 kolom pertama untuk dijadikan sebagai atribut\n",
        "X = dataset[:,0:4]\n",
        "# Pilih 3 kolom terakhir sebagai label\n",
        "y = dataset[:,4:7]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfZbiJ3e-N2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee291de2-9134-4d9b-9db3-034d37c84228"
      },
      "source": [
        "# Normalize\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
              "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
              "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
              "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
              "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
              "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
              "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
              "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
              "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
              "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
              "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
              "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
              "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
              "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
              "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
              "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
              "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
              "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
              "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
              "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
              "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
              "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
              "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
              "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
              "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
              "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
              "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
              "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
              "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
              "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
              "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
              "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
              "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
              "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
              "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
              "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
              "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
              "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
              "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
              "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
              "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
              "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
              "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
              "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
              "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
              "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
              "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
              "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
              "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
              "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
              "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
              "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
              "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
              "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
              "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
              "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
              "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
              "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
              "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
              "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
              "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
              "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
              "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
              "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
              "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
              "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
              "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
              "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
              "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
              "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
              "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
              "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
              "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
              "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
              "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
              "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
              "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
              "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
              "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
              "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
              "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
              "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
              "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
              "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
              "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
              "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
              "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
              "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
              "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
              "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
              "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
              "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
              "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
              "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
              "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
              "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
              "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
              "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
              "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
              "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
              "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
              "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
              "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
              "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
              "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
              "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
              "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
              "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
              "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
              "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
              "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
              "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
              "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
              "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
              "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
              "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
              "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
              "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
              "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
              "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
              "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
              "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
              "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
              "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
              "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
              "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
              "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
              "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
              "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
              "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
              "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
              "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
              "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
              "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
              "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
              "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzTyLXil-Qv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvEe50vt-YKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([    \n",
        "                    Dense(64, activation='relu', input_shape=(4,)),    \n",
        "                    Dense(64, activation='relu'),    \n",
        "                    Dense(3, activation='softmax'),])"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg6QBgkI-cHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujXfwHrt-dFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19d48b7d-5f2b-4fe7-fb95-07ae474f6dc7"
      },
      "source": [
        "hist = model.fit(X_train, Y_train, epochs=100)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0700 - accuracy: 0.3238\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.3429\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9953 - accuracy: 0.4762\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9658 - accuracy: 0.6095\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.6476\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9116 - accuracy: 0.6571\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.6571\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8559 - accuracy: 0.6571\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8268 - accuracy: 0.6571\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7979 - accuracy: 0.6571\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7689 - accuracy: 0.6571\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7403 - accuracy: 0.6571\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7125 - accuracy: 0.6571\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6571\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6762\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.7238\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.8095\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.9048\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.9143\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7810\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7333\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7143\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7429\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8095\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.9048\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.9524\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.9429\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.9143\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.9429\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.9238\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.9714\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.9619\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.9619\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.9524\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.9714\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.9333\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.9333\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.9524\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.9619\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.9619\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.9524\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.9619\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.9619\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9524\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9619\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9714\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9714\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9524\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9714\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9714\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9524\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9714\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9619\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9619\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9619\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9524\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9524\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9714\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9714\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9524\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9524\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9524\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9619\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9714\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9714\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9714\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9714\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9524\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9524\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9524\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9714\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9714\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9619\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9619\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9619\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9524\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9619\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9619\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9619\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9619\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9619\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9619\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9524\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9714\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9619\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9619\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9524\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9714\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9714\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9619\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9619\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9714\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9619\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9714\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9714\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9714\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9810\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9714\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9714\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDru6Ria-lrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2f545bde-0ae3-496e-fb1b-187f1de81b69"
      },
      "source": [
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11846271902322769, 0.9555555582046509]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TiTrGxu-xSj",
        "colab_type": "text"
      },
      "source": [
        "# Plot Loss dan Akurasi dari Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QHWUcMV-zKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udgVknDF-77s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e92006e0-cb41-4359-9fcb-bd7dea7be0a0"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dUFhNj4_Fqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d7b62cda-ac5e-4f26-c3f0-ae2de040e094"
      },
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAWmHX8J_9n6",
        "colab_type": "text"
      },
      "source": [
        "# Penggunaan Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9FxhBJ__EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense\n",
        "df = pd.read_csv('Iris.csv')\n",
        "df = df.drop(columns='Id')\n",
        "category = pd.get_dummies(df.Species)\n",
        "new_df = pd.concat([df, category], axis=1)\n",
        "new_df = new_df.drop(columns='Species')\n",
        "dataset = new_df.values\n",
        "X = dataset[:,0:4]\n",
        "y = dataset[:,4:7]\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)\n",
        "model = Sequential([    \n",
        "                    Dense(64, activation='relu', input_shape=(4,)),    \n",
        "                    Dense(64, activation='relu'),    \n",
        "                    Dense(3, activation='sigmoid'),])\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbofnre3ARKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nAkurasi telah mencapai >90%!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAzXWpb9ASBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "422aa212-9dc2-401b-b495-428d3b2bd25f"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=50, callbacks=[callbacks])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0713 - accuracy: 0.4190\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0534 - accuracy: 0.4952\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0383 - accuracy: 0.5143\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0233 - accuracy: 0.5238\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.5619\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.5714\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9728 - accuracy: 0.5905\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9535 - accuracy: 0.6476\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9321 - accuracy: 0.7714\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9095 - accuracy: 0.8667\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.8952\n",
            "Epoch 12/50\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.8689 - accuracy: 0.9375\n",
            "Akurasi telah mencapai >90%!\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8587 - accuracy: 0.9143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f817ada07f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMOHPsAsAWxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}